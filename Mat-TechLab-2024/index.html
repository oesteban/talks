<!DOCTYPE html>
<html>
  <head>
    <title>Mat-Tech Lab Meeting 12.11.2024</title>
    <meta charset="utf-8">
    <link rel="stylesheet" type="text/css" href="/talks/assets/asciinema-player/asciinema-player.css" />
    <style>
      @import url(https://fonts.googleapis.com/css?family=Roboto+Mono:400,700,400italic);

      .blur {
          -webkit-filter: blur(5px) opacity(.3);
          -moz-filter: blur(10px) opacity(.3);
          -o-filter: blur(5px) opacity(.3);
          -ms-filter: blur(5px) opacity(.3);
          filter: blur(5px) opacity(.3);
      }

      html {
        height: 100%;
      }
      body {
        font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
        height: 100%;
      }
      h1, h2, h3 {
        font-weight: 600;
        margin-bottom: 0;
      }

      .middle {
        margin: 0;
        position: absolute;
        top: 50%;
        width:100%;
        -ms-transform: translateY(-50%);
        transform: translateY(-50%);
      }

      .remark-slide-content { height: 100%; padding: 0; font-size: 16pt;}
      .remark-slide-content h1 { font-size: 2em; color: #738373; }
      .remark-slide-content h2 { font-size: 1.5em; color: #738373; }
      .remark-slide-content h3 { font-size: 1.2em; color: #738373; }
      .footnote {
        position: absolute;
        bottom: 0.5em;
        font-size: 0.7em;
  left: 6em;
      }
      li p { line-height: 1.25em; }

      .remark-slide-content>p { margin-left: 60px; }
      .remark-slide-content>ul { margin-left: 60px; }
      .remark-slide-content>ul li { margin-left: 0.8em; }

      .no-bullet > ul {
        list-style-type: none;
        padding-left:  0;
      }

      .no-bullet > ul > li > ul {
        padding-left:  2.8em;
      }

      .red { color: #fa0000; }
      .blue { color: #0000fa; }
      .green { color: #698b69; }

      a, a > code {
        color: rgb(249, 38, 114);
        text-decoration: none;
      }
      code {
        background: #e7e8e2;
        border-radius: 3px;
      }
      .remark-code, .remark-inline-code { font-family: 'Roboto Mono'; }
      .large .remark-code, .large .remark-inline-code { font-size: 0.8em; }
      .remark-code-line-highlighted     { background-color: #373832; }
      .pull-left {
        float: left;
        width: 45%;
      }
      .pull-right {
        float: right;
        width: 45%;
        height: 75%;
      }
      .pull-right ~ p {
        clear: both;
      }
      #slideshow .slide .content code {
        font-size: 0.8em;
      }
      #slideshow .slide .content pre code {
        font-size: 0.9em;
        padding: 15px;
      }
      .section-separator .middle {
        margin-left: 210px;
        width: 80%;
      }

      .fa-solid {
        color: #026c00;
      }
      .fa-brands {
        color: #026c00;
      }
      .fa-blank {
  color: #ffffff;
      }

      em {
        color: #026c00;
      }

      strong {
        color: #026c00;
      }

      a { color: #026c00; text-decoration: underline}

      .gray-text {
        color: #888;
      }
      .gray-text em, .gray-text strong {
        color: #888;
      }

      .perma-sidebar {
        float: left;
        background-color: #009933;
        color: #f4f4f4;
        width: 40px;
        height: 100%;
        padding: 0;
        margin: 0 2em 0 0;
        text-align: center;
      }
      .perma-sidebar p {
        text-align: left;
        font-size: 80%;
        height: 35px;
        width: 670px;
        margin: 320px 0 0 -315px;
      }
      .perma-sidebar h2:last-of-type, .perma-sidebar h3:last-child {
        color: #d2c295;
      }

/*      .sidebar-slug {
          bottom: 12px;
          left: 0;
          position: absolute;
          width: 210px;
          text-align: center;
      }
      .sidebar-slug img {
          width: 180px;
      }*/

      .svg-reportlet { width: 75%; }

      /* Slide-specific styling */
      #slide-inverse .footnote {
        bottom: 12px;
        left: 20px;
      }
      #slide-how .slides {
        /*font-size: .9em;*/
        position: absolute;
        top:  151px;
        right: 140px;
      }
      #slide-how .slides h3 {
        margin-top: 0.2em;
      }
      #slide-how .slides .first, #slide-how .slides .second {
        padding: 1px 20px;
        height: 90px;
        width: 120px;
        -moz-box-shadow: 0 0 10px #777;
        -webkit-box-shadow: 0 0 10px #777;
        box-shadow: 0 0 10px #777;
      }
      #slide-how .slides .first {
        background: #fff;
        position: absolute;
        top: 20%;
        left: 20%;
        z-index: 1;
      }
      #slide-how .slides .second {
        position: relative;
        background: #fff;
        z-index: 0;
      }

      /* Two-column layout */
      .left-column {
        width: 23%;
        height: 82%;
        float: left;
      }
        .left-column h2:last-of-type, .left-column h3:last-child {
          color: #000;
        }
      .right-column {
        width: 65%;
        float: right;
        padding-top: 1em;
      }
      /* Two-column layout (40% left) */
      .left-column2 {
        width: 35%;
        height: 85%;
        float: left;
      }
        .left-column2 h2:last-of-type, .left-column2 h3:last-child {
          color: #000;
        }
      .right-column2 {
        width: 50%;
        float: right;
        padding-top: 1em;
        margin-right: 2.5em;
      }
      /* Two-column layout (60% left) */
      .left-column3 {
        display: block;
        width: auto;
        height: 85%;
        margin: 0 32% 0 5%;
      }
        .left-column3 h2:last-of-type, .left-column3 h3:last-child {
          color: #000;
        }

      .left-column3 li {
        margin-left: 25px;
      }

      .right-column3 {
        width: 30%;
        float: right;
        padding-top: 1em;
      }
      /* Two-column layout (even split) */
      .left-column-mid {
        width: 45%;
        float: left;
      }
      .right-column-mid {
        width: 45%;
        float: right;
      }
      /* Two-column layout (flipped) */
      .left-column-inv {
        color: #777;
        width: 75%;
        height: 92%;
        float: left;
      }
        .left-column h2:last-of-type, .left-column h3:last-child {
          color: #000;
        }
      .right-column-inv {
        width: 20%;
        float: right;
        padding-top: 1em;
      }
      .caption {
          font-size: 0.7em;
      }
      .slide-slug {
          bottom: 12px;
          opacity: .5;
          position: absolute;
          left: 4em;
      }

      .small code {
        font-size: 9pt;
      }
      .tiny code {
        font-size: 8.5pt;
      }

      .small {
        font-size: 0.7em;
      }

      .larger {
        font-size: 1.4em;
      }

      .large {
        font-size: 1.6em;
      }

      .boxed-content {
        float: left;
        display: block;
        width: 89%;
        padding-right: 4%;
      }

      .boxed-bottom {
        clear: both;
        margin-top: 0px;
      }
/*
      .distribute {
        display: flex;
        justify-content: space-between;
        flex-direction: column;
        height: 100%;
        width: 100%;
      }*/

      .distribute {
        display: flex;
        justify-content: space-between;
        flex-direction: column;
        height: 80%;
        width: 100%;
      }

      .cut-right {
        margin-right: 100px;
      }

      .align-right {
        text-align: right;
      }

      .rotate{
        -webkit-transform: rotate(-90deg);
        -moz-transform: rotate(-90deg);
        -o-transform: rotate(-90deg);
        -ms-transform: rotate(-90deg);
        transform: rotate(-90deg);
      }

      .hidden-text {
        color: transparent; /* make the text invisible */
        user-select: none; /* prevent selection of the text */
      }

      .pad-left {
        padding-left: 2.0em;
      }
      .install-cmd {
          top: 20px;
          position: absolute;
          right: 4em;
      }
      figure {
        display: block;
        margin-left: auto;
        margin-right: auto;
        font-size: 8pt;
      }
      figcaption {
        text-align: right;
        font-size: 1.2em;
      }

      .program-table td:nth-child(2) {
        font-size: 1.2em;
        
      }
      .program-table td:nth-child(1) {
        font-size: 0.9em;
        color: #999;
        padding-right: 20px;
      }

      .people-table td:nth-child(1) {
        padding-right: 20px;
      }
      .people-table img {
        object-fit: cover;
        width: 200px;
        height: 200px;
        filter: grayscale(1);
      }

      .many-people-table td:nth-child(1) {
        padding-right: 20px;
      }
      .many-people-table td:nth-child(1) img {
        object-fit: cover;
        width: 80px;
        height: 80px;
      }

      .top-right {
        font-size: 0.8em;
        position:  absolute;
        width: 100px;
        text-align: center;
        padding: 0;
        margin: 0;
        top: 0;
        right: 5%;
      }
      .pad-top {
        padding-top: 30px;
      }

      div.vertical-center {
        /*left: 0;*/
        width:  85%;
        margin: -100px 20px 40px 100px;
        position: absolute;
        text-align: center;
        top: 50%;
      }

      div.white-bg {
        rgba(0, 0, 0, 0.6);
      }
    </style>
  </head>
  <body>
<script src="/talks/assets/asciinema-player/asciinema-player.min.js"></script>
<script src="https://kit.fontawesome.com/7e31cfd31d.js" crossorigin="anonymous"></script>
<script type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_CHTML">
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$','$'], ['\\(','\\)']],
      processEscapes: true},
      jax: ["input/TeX","input/MathML","input/AsciiMath","output/CommonHTML"],
      extensions: ["tex2jax.js","mml2jax.js","asciimath2jax.js","MathMenu.js","MathZoom.js","AssistiveMML.js", "[Contrib]/a11y/accessibility-menu.js"],
      TeX: {
      extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"],
      equationNumbers: {
      autoNumber: "AMS"
      }
    }
  });
</script>


<textarea id="source">

name: title
layout: true
class: center
---
layout: false
count: false


.center[
<a href="https://oesteban.github.io/talks/Mat-TechLab-2024/">
  <img src="images/qr-talk-url.svg" alt="workflow" style="width: 20%" />
  <br />
  https://oesteban.github.io/talks/Mat-TechLab-2024/
</a>

<br />
<br />

## Repeatable Research: Don't Repeat History Fishing for Dead Salmons

Oscar Esteban &lt;<code>phd@oscaresteban.es</code>>

<br />

### Mathematical Technologies Lab 12.11.24
]

???


---
name: newsection
layout: true

.perma-sidebar[
<p class="rotate">
<a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="border-width:0; height: 20px; padding-top: 6px;" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a>
  <span style="padding-left: 10px; font-weight: 600;">Esteban | Mat-Tech Lab | Repeatable Research</span>
</p>
]

---

# About me

.right-column3.center[
(Link to talk)
<a href="https://oesteban.github.io/talks/Mat-TechLab-2024/">
  <img src="images/qr-talk-url.svg" alt="workflow" style="width: 100%" />
  <br />
  https://oesteban.github.io/talks/Mat-TechLab-2024/
</a>
]


.pad-top.left-column3[
.people-table.larger[

| | |
|---:|---|
| ![oscar-esteban](https://www.axonlab.org/images/teampic/OscarEsteban-300x300.jpg) | **Oscar Esteban** <br /> Research & Teaching FNS Fellow <br /> Dept. of Radiology, CHUV |
]

I'm a computational neuroscientist and open science advocate dedicated to improving the reproducibility of neuroimaging research.
At Stanford University, we created *fMRIPrep* and initiated [*NiPreps*](https://www.nipreps.org), focusing on ensuring robust, standardized research across studies.
I currently lead the *Human Connectome PHantom project*, tackling the challenge of characterizing the reliability of brain networks.

**My mission**: to bridge the gap between cutting-edge science and the tools that drive it, making research **more transparent and dependable**.

**Today's worry**: are we heading toward a re-edition of the dead salmon realization?
]

---

.boxed-content[
.center.small[
<object data="images/Bennett-Salmon-2009.pdf" type="application/pdf" style="margin-top: 15px;" width="100%" height="600px">
    <embed src="images/Bennett-Salmon-2009.pdf">
        <p>This browser does not support PDFs. Please download the PDF to view it: <a href="images/program.pdf">Download PDF</a>.</p>
    </embed>
</object>
http://prefrontal.org/files/posters/Bennett-Salmon-2009.pdf
]
]

---

.vertical-center[
.center[
.large.gray-text[
<i>While we must guard against the elimination of
legitimate results through Type II error, the alternative
of continuing forward with uncorrected statistics cannot
be an option.</i>
]

[Redux —of the poster, not the salmon— by Bennett et al. (*Journal of Serendipitous and Unexpected Results*, 2009)](https://www.mathematik.uni-rostock.de/storages/uni-rostock/Alle_MNF/Mathematik/Struktur/Lehrstuehle/Analysis-Differentialgleichungen/salmon-fMRI.pdf)

]
]

???

while this comes from structured noise in the data

the neuroimaging pipeline is complex and souces of noise are everywhere

---

# Today's issue: analytical flexibility

<figure style="width: 65%">
![:img narps, 100%](images/narps-paper.png)
<figcaption>From <a href="https://doi.org/10.1038/s41586-020-2314-9">Botvinik-Netzer et al. 2020</a>;
doi:![:doi](10.1038/s41586-020-2314-9)</figcaption>
</figure>

---

# Analytical variability is not limited to fMRI

<figure style="width: 70%">
![:img ismrm-challenge, 100%](images/tractography-challenge.png)
<figcaption>From <a href="https://doi.org/10.1038/s41467-017-01285-x">Maier-Hein et al. 2017</a>;
doi:![:doi](10.1038/s41467-017-01285-x)</figcaption>
</figure>

---
count:false

# Analytical variability is not limited to fMRI

.vertical-center[
.center.white-bg[
.large[
***Tractography-based connectomes are dominated by false-positive connections***
]

Draft title (2015) - doi:[10.1101/084137](https://doi.org/10.1101/084137)

]
]
<div style="background-image: url(images/tractography-challenge.png); background-size: cover; height: 80%; width: 80%; margin-left: 180px; opacity: 0.1">
</div>

---

.vertical-center[
.center.white-bg[
.large[
**Are we repeating history?**
]
]
]

---
count:false

.vertical-center[
.gray-text[Are we repeating history?]
.large[

**Why should we care about reproducibility?**
]
]

---
count:false

.vertical-center[
.gray-text[Are we repeating history?]
.large[

**Why should we care about reproducibility?**

.gray-text[What does 'reproducibility' mean?]
]
]

---

.center[
<img src="../../../talks/assets/reproducible-definition-grid.svg" alt="reproducibility-grid" style="width: 68%" />
.small[
*The Turing Way project* illustration by Scriberia. Used under a CC-BY 4.0 licence. doi:<a href="https://doi.org/10.5281/zenodo.3332807">10.5281/zenodo.3332807</a>.]
]

---

# More reliable measurements

.center[
.boxed-content[
<img src="images/reproducible-definition-grid-axes-0.png" alt="reproducibility axes" style="width: 65%" />


[Esteban, (2024)](https://doi.org/10.31219/osf.io/42bsu) [[Methods for analyzing large neuroimaging datasets](https://osf.io/d9r3x/)]
]
]

---
count: false

# More reliable measurements

.center[
.boxed-content[
<img src="images/reproducible-definition-grid-axes-1.png" alt="reproducibility axes" style="width: 65%" />


[Esteban, (2024)](https://doi.org/10.31219/osf.io/42bsu) [[Methods for analyzing large neuroimaging datasets](https://osf.io/d9r3x/)]
]
]

---
count: false

# More reliable measurements

.center[
.boxed-content[
<img src="images/reproducible-definition-grid-axes-2.png" alt="reproducibility axes" style="width: 65%" />


[Esteban, (2024)](https://doi.org/10.31219/osf.io/42bsu) [[Methods for analyzing large neuroimaging datasets](https://osf.io/d9r3x/)]
]
]

---
count: false

# More reliable measurements

.center[
.boxed-content[
<img src="images/reproducible-definition-grid-axes-3.png" alt="reproducibility axes" style="width: 65%" />


[Esteban, (2024)](https://doi.org/10.31219/osf.io/42bsu) [[Methods for analyzing large neuroimaging datasets](https://osf.io/d9r3x/)]
]
]

---

# Where do we start?

<br />
<br />

.boxed-content[
<img src="../../../talks/assets/neuroimaging-workflow-large.svg" alt="workflow" style="width: 100%" />


.center[
[Esteban et al., (2020)](http://doi.org/10.1038/s41596-020-0327-3);
[Niso et al., (2022)](https://doi.org/10.1016/j.neuroimage.2022.119623)
]
]

???

---

# Where do we start?

.boxed-content[
<br />
.center[
<img src="../../../talks/assets/neuroimaging-workflow-large.svg" alt="workflow" style="width: 70%" />
]
<br />

.larger[
Data collection <i class="fa-solid fa-circle-right"></i> easy to standardize (BIDS, scanners' software)

Statistical modeling <i class="fa-solid fa-circle-right"></i> keep analytical flexibility not to stifle the development of new ideas

Preprocessing <i class="fa-solid fa-circle-right"></i> offers an **opportunity** to reduce analytical flexibility and **enable** cross-study comparisons
]

]

---

.vertical-center[
.center.white-bg[
.large[
**Standardization** .gray-text[<i>of preprocessing</i>]
]
]
]


---

# Why do data require preprocessing?

.boxed-content[

<br />


.large.center[
<i class="fa-solid fa-circle-exclamation"></i> MRI measurements *generally* **cannot** be directly analyzed. <i class="fa-solid fa-circle-exclamation"></i>
]

<br />

.pull-left[
.center.larger[<i class="fa-solid fa-map-pin"></i> **Spatiotemporal location**]

signal drawn from the same location and accurate time at all time points,
sampled consistently with the analysis' design (e.g., surface, volume)
]

.pull-right[
.center.larger[<i class="fa-solid fa-location-crosshairs"></i> **Signal *validity***]

extraction of confounds, identification/accounting for artifacts, spatiotemporal filtering for denoising, etc.
]

<br />

.boxed-bottom.large.center[
**End goal**: minimize false positives without increasing false negatives
]
]

---

# Why do data require preprocessing?

.boxed-content[

<br />
<br />

.large[
All analyses require consistency and accuracy in **spatiotemporal location**.
]

<br />
.larger[

<i class="fa-solid fa-circle-right"></i> **within runs** (head-motion, slice-timing),

<i class="fa-solid fa-circle-right"></i> **within individuals** (coregistration between runs, coregistration with anatomy [T1w images, surfaces, etc.], susceptibility distortion), and

<i class="fa-solid fa-circle-right"></i> **across subjects** (spatial normalization)

]

]

---

## Example: susceptibility distortion


<p align="center">
<img src="images/sdc-the-problem.svg" width="80%" /><br />
</p>

---

# Why do data require preprocessing?
<br />

.boxed-content[
.large[
All analyses must consider confounders and covariates that undermine the **validity** of the measurements.
]
.larger[
* confounders such as global signals, signal drifts, DVARS, etc.

* spatiotemporal filtering to increase SNR,

* known artifacts such as head-motion parameters and derivations, etc.
]

<br />

.boxed-bottom.large[
**Minimal preprocessing**: .gray-text[*fMRIPrep* is *conservative* in that it will not regress out signals or apply intended smoothing kernels]
]
]

---

# Preprocessing & Reproducibility

.boxed-content[

.large[
The reproducibility of preprocessing sets bounds to the reproducibility of downstream analyses.
]

.larger[
* NARPS ([Botvinik-Nezer et al., 2020](https://doi.org/10.1038/s41586-020-2314-9)): single dataset, 70 teams, 9 <i>ex-ante</i> hypotheses.

  <i class="fa-solid fa-circle-right"></i> Striking analytical variability (even with teams using same preprocessing)

* [Li et al., (2024)](https://doi.org/10.1038/s41562-024-01942-4): single test-retest dataset, 5 pipelines

  <i class="fa-solid fa-circle-right"></i> Moderate inter-pipeline agreement, limiting cross-study <s>reproducibility</s> [replicability]
]
]

---

# Preprocessing & Reproducibility

.boxed-content[
<br />
<br />

.large[
Beyond analytical variability, other sources of variability are on the way:
]
.larger[
* Random seeds

  <i class="fa-solid fa-circle-right"></i> Keep track (*do not fix*) and report.

* [Chatelain et al., (2023)](https://doi.org/10.48550/arXiv.2307.01373): Random rounding of floating-point calculations.

  <i class="fa-solid fa-circle-right"></i> Uncovered substantial changes between patch-releases of *fMRIPrep*
]


]

---

# fMRIPrep: bird's eye picture

.boxed-content.center[
<br />
<br />
<img src="https://github.com/oesteban/fmriprep/raw/f4c7a9804be26c912b24ef4dccba54bdd72fa1fd/docs/_static/fmriprep-21.0.0.svg" width="100%" />
]

---

.pull-left.center[
<img src="images/fmriprep-anatomical.png" width="90%" />
]

.pull-right[

# Anatomical processing

.large[
Delivered within *sMRIPrep*
]

.larger[

<i class="fa-solid fa-circle-right"></i> Denoising

<i class="fa-solid fa-circle-right"></i> INU correction

<i class="fa-solid fa-circle-right"></i> Averaging (multi-session)

<i class="fa-solid fa-circle-right"></i> Brain extraction

<i class="fa-solid fa-circle-right"></i> Spatial normalization

<i class="fa-solid fa-circle-right"></i> Brain tissue segmentation

<i class="fa-solid fa-circle-right"></i> Surface reconstruction
]


]

---

.pull-left.center[
<br />
<br />
<img src="images/fmriprep-functional.png" width="100%" />
]

.pull-right[

# Functional processing

.larger[

<i class="fa-solid fa-circle-right"></i> Reference volume

<i class="fa-solid fa-circle-right"></i> Slice-timing (optional)

<i class="fa-solid fa-circle-right"></i> Head-motion (estimation)

<i class="fa-solid fa-circle-right"></i> Susceptibility distortion (estimation)

<i class="fa-solid fa-circle-right"></i> Co-registration with anatomical T1w

<i class="fa-solid fa-circle-right"></i> Resampling into specific spaces

<i class="fa-solid fa-circle-right"></i> Confound collection
]


]

---

# *TemplateFlow*

.boxed-content.center[
<img src="https://www.templateflow.org/assets/templateflow_fig-birdsview.png" width="70%" /><br />
(<a href="https://doi.org/10.1038/s41592-022-01681-2">Ciric et al., 2022</a>)
]

---

# *SDCFlows*

.boxed-content[
.large[
SDC <i class="fa-solid fa-circle-right"></i> Susceptibility-derived Distortion Correction
]
<br />

.larger[
*SDCFlows* "caters" preprocessed fieldmap estimations for *fMRIPrep* to reconstruct the nonlinear displacements field to revert geometrical distortion.
]

.center[<img src="images/sdc-the-problem.svg" width="40%" />]
]

---

# Standardizing preprocessing: visual reports

.boxed-content[
<iframe src="https://fmriprep.s3.amazonaws.com/bootcamp-geneva-2024/sub-15.html" width="100%" height="540px" style="border: 0; margin-top: 15px" />
]
---

# Standardizing preprocessing: community building

.large[fMRI practitioners have massively adopted *fMRIPrep* globally:]

<p align="center">
<img src="images/20240502_weekly.png" width="85%" /><br />
</p>

---

# Standardizing preprocessing: community building


<p align="center">
<img src="images/20240502_weekly.png" width="80%" /><br />
</p>


.large.center[<i class="fa-solid fa-circle-right"></i> which has permitted the creation of a large community.]

---

# Building a community was important to *fMRIPrep*

.boxed-content.large[
.no-bullet[
* <i class="fa-solid fa-comments"></i> Feedback & support:
   * error & bug reports <i class="fa-solid fa-bug" style="color: #ff4c26;"></i> help development,
   * feature requests <i class="fa-solid fa-lightbulb" style="color: #00bc07;"></i> help driving a roadmap,
   * questions <i class="fa-solid fa-circle-question"></i> are the entry point to deliver support
      * [<i class="fa-solid fa-bullhorn"></i> NeuroStars.org](https://neurostars.org)

* <i class="fa-solid fa-user-plus"></i> Engage contributors (see [our guidelines](https://www.nipreps.org/community/CONTRIBUTING/)):
   * documentation, assistance debugging, code patches, everything counts!

* <i class="fa-solid fa-globe"></i> Reach out, increase user-base.
]
]

---

# Standardizing preprocessing: software versions

.larger[
<i class="fa-solid fa-circle-right"></i> It's critical to report **exact versions**

<i class="fa-solid fa-circle-right"></i> Semantics inform about compatibility: **24.0.1**

<i class="fa-solid fa-circle-right"></i> Long-term support (LTS) program.

]

<p align="center">
<img src="images/20240502_versionstream.png" width="85%" /><br />
</p>

---

<p align="center">
<img src="../../../talks/assets/nipreps-chart.png" width="63%" /><br />
<em>NiPreps</em> (<a href="https://doi.org/10.31219/osf.io/ujxp6">Esteban et al., 2020</a>)
</p>

---

# *NiPreps* produce *analysis-grade* data

.boxed-content[
<br />
.larger.center[
"*analysis-grade*" data <i class="fa-solid fa-circle-right"></i> data **directly consumable by analyses**
]

.pull-left[
<br />
<br />
*Analysis-grade* data is an analogy to the concept of "*sushi-grade (or [sashimi-grade](https://en.wikipedia.org/wiki/Sashimi)) fish*" in that both are:

.large[<i class="fa-solid fa-circle-right"></i> **minimally preprocessed**,]

and

.large[<i class="fa-solid fa-circle-right"></i> **safe to consume** directly.]
]

.pull-right.center[
<img src="../../../talks/assets/nipreps-transparent.png" width="100%" />
<a href="https://www.nipreps.org"><img src="../../../talks/assets/qr-nipreps-url.svg" width="40%" /><br />
www.nipreps.org</a>
]
]

---

.vertical-center[
.center.white-bg[
.large[
**Repetition** .gray-text[<i>of MR connectomics</i>]
]
]
]

---

# Data — The Human Connectome PHantom (HCPh)

.right-column3[
.larger[
**Registered Report** <br />
Stage 1 Accepted-in-principle:

<a href="https://doi.org/10.17605/OSF.IO/VAMQ6"><img src="../ISMRM2024/images/qr-RR.svg" alt="workflow" style="width: 85%" />
Provins et al., (2023)</a>


]
]

.left-column3[
<img src="https://www.axonlab.org/hcph-sops/assets/images/cohort1.png" alt="workflow" style="width: 87%" />
]

---

# The paradox (Prof. C. Chambers)

--

<br />
<br />
<br />

## Results determine careers

<br />

--

and

<br />

## Resarchers SHOULD NOT determine results.

---

# What are Registered Reports?

<p align="center">
<img src="../BHD2023/images/RRs-traditional-before-review.png" width="90%" /><br /><br />
</p>

---

# What are Registered Reports?

<p align="center">
<img src="../BHD2023/images/RRs-traditional-after-review.png" width="90%" /><br /><br />
</p>

---

# What are Registered Reports?

<p align="center">
<img src="../BHD2023/images/RRs-workflow.png" width="90%" /><br /><br />
</p>

---

.vertical-center[
.center.white-bg[
.large[
**Results do not matter**
]
]
]

---
count: false

.vertical-center[
.center.white-bg[
.large[
**Results** [*whether positive or negative*] **do not matter**
]
]
]

---

.vertical-center[
.center.white-bg[
.large[
**QA/QC**
]
]
]

---

# QA/QC of the neuroimaging worflow

<br />
<br />

.boxed-content[
<img src="../ISMRM2024/images/09-qaqc-workflow.png" alt="workflow" style="width: 100%" />

<br />

.align-right[
([Provins et al., 2023](http://doi.org/10.3389/fnimg.2022.1073734))
]
]

???

With a corresponding feedback loop.
For instance, we may need to revise nuisance regression.

---

# QA/QC protocols: 'Swiss-cheese security model'

.boxed-content[
.center[
<img src="../ISMRM2024/images/09-qaqc-workflow.png" alt="workflow" style="width:60%" />

<img src="../ISMRM2024/images/swiss-cheese.svg" alt="swiss-cheese" style="width:60%" />

.small[
[BenAveling @ wikipedia](https://en.wikipedia.org/wiki/Swiss_cheese_model#/media/File:Swiss_cheese_model_textless.svg)
]
]

]

???

For those with knowledge about security protocols, this approach will surely evoke the Swiss cheese model.

The model assumes that all QC checkpoints will have holes through which data progresses toward analysis.

By layering several QC checkpoints looking at the data in different ways, we make sure that images with potential to bias the results do not make all the way through the workflow.

---

# Plan ahead: SOPs

.boxed-content[
.distribute.large[

* You want to have **Standard Operating Procedures**, a document:

  * prescribing all details of analysis,
  * particularly establishing QC/QA points and triggered actions,
  * establishing exclusion criteria,
  * accessible to all involved stakeholders.


* Check out our *SOPs-cookiecutter* project:

  * [GitHub template-repository](https://github.com/nipreps/sops-cookiecutter)
  * [Rendered example](https://www.nipreps.org/sops-cookiecutter/)

]
]

---

# HCPh's SOPs

.boxed-content[
<iframe src="https://www.axonlab.org/hcph-sops/" width="100%" height="510px" style="border: 0; margin-top: 15px"></iframe>
.center.small[https://www.axonlab.org/hcph-sops/]
]

---

# Bias introduced by defacing

.boxed-content.center[
<img src="images/ba-traditional.png" alt="defacing-RR" style="width: 60%" />
.small[
([Provins et al., 2023](https://rr.peercommunityin.org/articles/rec?id=346))
]
]

---
count:false

# Bias introduced by defacing

.boxed-content.center[
<img src="images/animated_plot.gif" alt="defacing-RR" style="width: 60%" />
.small[
([Provins et al., 2023](https://rr.peercommunityin.org/articles/rec?id=346))
]
]

---
count:false

# Bias introduced by defacing

.boxed-content.center[
<img src="images/ba-optimized.png" alt="defacing-RR" style="width: 60%" />
.small[
([Provins et al., 2023](https://rr.peercommunityin.org/articles/rec?id=346))
]
]

---

# Bias introduced by defacing

.boxed-content.center[
<img src="images/figure2.png" alt="defacing-RR" style="width: 90%" /><br />
.small[
([Provins et al., 2023](https://rr.peercommunityin.org/articles/rec?id=346))
]
]



---

# Conclusion

.boxed-content[
* .large[Incentive structure unchanged over 15yr.]

    * Analytical variability as the new multiple-comparisons problem
    * Transparency & reproducibility as a solution

* .large[Standardization]

    * The case of *fMRIPrep*
    * The *NiPreps* community

* .large[Repetition]

    * The HCPh study

* .large[QA/QC]

    * Registered Reports
    * Tools: SOPs & MRIQC
    * The defacing effects on QA/QC

]

???


---
layout: false
count: false


.center[
<a href="https://oesteban.github.io/talks/ISMRM2024/"><img src="images/qr-talk-url.svg" alt="workflow" style="width: 20%" /></a>

## Thanks

<br />
<br />

### Oscar Esteban &lt; phd@oscaresteban.es >

Mat-Tech Lab 12.11.24

Funding: [SNSF 185872](https://data.snf.ch/grants/grant/185872), [RF1MH121867](https://reporter.nih.gov/project-details/10260312), [CZI EOSS5-000266](https://chanzuckerberg.com/eoss/proposals/nipreps-a-community-framework-for-reproducible-neuroimaging/)

]

???

</textarea>
    <script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
    <script>
      // Use: ![:img Alt text with spaces but not commas, 50%](image.png)
      remark.macros.img = function (altText, width) {
        var url = this;
        return '<img alt="' + altText + '" src="' + url + '" style="width: ' + width + '" />';
      };
      // Use: ![:video](10.5129/10234)
      remark.macros.video = function (width) {
        var url = this;
        return '<video src="' + url + '" width="' + width + '" preload="auto" controls />';
      };
      // Use: ![:doi](10.5129/10234)
      remark.macros.doi = function () {
        var doi = this;
        return '<a href="https://doi.org/' + doi + '">' + doi + '</a>';
      };

      var slideshow = remark.create({
          highlightStyle: 'monokai',
          highlightLanguage: 'remark',
          highlightLines: true,
          countIncrementalSlides: false,
          highlightSpans: true,
          ratio: '16:9'
      });
    </script>
  </body>
</html>
